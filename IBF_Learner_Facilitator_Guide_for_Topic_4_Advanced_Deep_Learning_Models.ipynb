{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IBF Learner/Facilitator Guide for Topic 4 -  Advanced Deep Learning Models",
      "provenance": [],
      "collapsed_sections": [
        "uePIrjqGAJDw",
        "WKgjQ1Cp3ck2",
        "dYHoIlOnTOIx",
        "9hi9pgiAb_Wc",
        "bj0_-g09jL-S",
        "mbl5w8vDjTwU",
        "gfhIrE2fDRDv",
        "6VgV9NCaZxUb",
        "4kFBAGkA97hH",
        "SuR1qtSVAu1a",
        "WGzjGBNsD2Zn",
        "OZOBUJ02-rA9",
        "gLlwee1LY0CA",
        "WExIKZPn3qX-",
        "Ij_t2sHPkNoF",
        "loQBoU1AFk66",
        "uvht4o67PiUU",
        "9wEuxiX_j56O",
        "cN_Ku2X91WlQ",
        "jPXFAwUl1b5V",
        "WgQGI9_41fSJ",
        "uY6tbfDe1j3k",
        "BgViJ2IO1ndb",
        "oD3qK9B4liVT",
        "TO3WCmo2nB-Q",
        "mQjlvPJKbuz1",
        "TsnfnOpnb5WG",
        "82INGsfHb_40",
        "KvXRTJg9cGVC",
        "xdCaSULmc786",
        "4Ta9YWWZdbiF",
        "D6mpaNGixeDu",
        "YRck3uIwyeLo",
        "6naCWJHxygNk",
        "u4eKE0nEyxfk",
        "kMaVg1zTKCIG",
        "p_rU994OlLbm",
        "4VI_2v-MlQT5",
        "AliO7-3ZVY0R"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN9p4qrXN9ms"
      },
      "source": [
        "# Topic 4 Advanced Deep Learning Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlwee1LY0CA"
      },
      "source": [
        "## Topic 4.1 Time Series Forecasting with Recurrent Neural Network (RNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WExIKZPn3qX-"
      },
      "source": [
        "### RNN/LSTM/GRU and Input Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_ygHw4aQTBK"
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "\n",
        "batch = 5 \n",
        "feature = 10 # could be the embedding size\n",
        "hidden_size = 20 \n",
        "timesteps = 3 # sequence length \n",
        "\n",
        "inputs = np.random.randn(batch, timesteps, feature)\n",
        "rnn = tf.keras.layers.SimpleRNN(hidden_size)\n",
        "\n",
        "h_out = rnn(inputs)\n",
        "print('Output size (batch, hidden_size) = ', h_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XirvKmDdSJw4"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "batch = 5 \n",
        "feature = 10 # could be the embedding size\n",
        "hidden_size = 20 \n",
        "timesteps = 3 # sequence length \n",
        "\n",
        "inputs = np.random.randn(batch, timesteps, feature)\n",
        "lstm = tf.keras.layers.LSTM(hidden_size)\n",
        "\n",
        "h_out = lstm(inputs)\n",
        "print('Output size (batch, hidden_size) = ', h_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBYPOmuISOeB"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "batch = 5 \n",
        "feature = 10 # could be the embedding size\n",
        "hidden_size = 20 \n",
        "timesteps = 3 # sequence length \n",
        "\n",
        "inputs = np.random.randn(batch, timesteps, feature)\n",
        "gru = tf.keras.layers.GRU(hidden_size)\n",
        "\n",
        "h_out = gru(inputs)\n",
        "print('Output size (batch, hidden_size) = ', h_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij_t2sHPkNoF"
      },
      "source": [
        "### Time Series Forcasting with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loQBoU1AFk66"
      },
      "source": [
        "#### Stock Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIbyHlONNEch"
      },
      "source": [
        "##### Step 1: Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRdmC-YFmOj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b33ybIGF0Y7"
      },
      "source": [
        "stock_dataset = pd.read_csv('DBS.csv',usecols=['Date','Close'])\n",
        "\n",
        "stock_dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkNmA9zLGG05"
      },
      "source": [
        "stock_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVaku_kZGL8s"
      },
      "source": [
        "dataset = stock_dataset.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Market Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2nZgeMZGRFU"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8DAyY2cGWQk"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqRm6PKHGayh"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRIu1hXjGkle"
      },
      "source": [
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(X)]\n",
        "y_test = y[train_size:len(y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWYACpXrGo7m"
      },
      "source": [
        "feature = 1\n",
        "hidden_size = 5\n",
        "input_size = 1\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B2sRx7NMFp"
      },
      "source": [
        "##### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt94ktzyGv3m"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sggVP6RNOp5"
      },
      "source": [
        "##### Step 3: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBL1xEEG1xc"
      },
      "source": [
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mse', optimizer=ADAM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbQB9oJINShL"
      },
      "source": [
        "##### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFjNAbZdG6w6"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hZd313DNVYI"
      },
      "source": [
        "##### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH6ALXk3HFy8"
      },
      "source": [
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yhd4as3HKnf"
      },
      "source": [
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kuj8ufeIqZJ"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdGMxt_UFX_f"
      },
      "source": [
        "### Impact of Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMuaNYUHsGw"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.2)\n",
        "model.compile(loss='mse', optimizer=ADAM)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1000)\n",
        "\n",
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()\n",
        "\n",
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye9lb-AFJjPG"
      },
      "source": [
        "### Impact of Sequence Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjl_4ur4JnT1"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)\n",
        "\n",
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(X)]\n",
        "y_test = y[train_size:len(y)]\n",
        "\n",
        "feature = 1\n",
        "hidden_size = 5\n",
        "input_size = 1\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mse', optimizer=ADAM)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1000)\n",
        "\n",
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()\n",
        "\n",
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1MEiAzGLOtU"
      },
      "source": [
        "### Impact of Hidden Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Sr1m-4LSFX"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)\n",
        "\n",
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(X)]\n",
        "y_test = y[train_size:len(y)]\n",
        "\n",
        "feature = 1\n",
        "hidden_size = 2\n",
        "input_size = 1\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mse', optimizer=ADAM)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1000)\n",
        "\n",
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()\n",
        "\n",
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FotNVrxFj3oX"
      },
      "source": [
        "#### Activity: Stock Market Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKNwEDCckpQe"
      },
      "source": [
        "##### Step 1: Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0siiVG5kGo8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYop_mB4kHfM"
      },
      "source": [
        "stock_dataset = pd.read_csv('AAPL.csv',usecols=['Date','Close'])\n",
        "\n",
        "stock_dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVA6ROofkOdN"
      },
      "source": [
        "stock_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yj-6P_jkQ7Y"
      },
      "source": [
        "dataset = stock_dataset.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Market Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgFqzd3gkTY3"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFhHW-ckkVTe"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPJLWMJAkXW3"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enKbd7cxkaYG"
      },
      "source": [
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(X)]\n",
        "y_test = y[train_size:len(y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk8wKQKdkeJo"
      },
      "source": [
        "feature = 1\n",
        "hidden_size = 5\n",
        "input_size = 1\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HlelLZ4khAt"
      },
      "source": [
        "##### Step 2 Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvTi8f0SklHQ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQsNgdlUktK2"
      },
      "source": [
        "##### Step 3: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd3r6RzCkt7Y"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSXelAoSkwVv"
      },
      "source": [
        "##### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAFU0Y_lk0MC"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTnLEc5uk4oV"
      },
      "source": [
        "##### Step 5: Evaluate teh Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f-N1FgVk7Uz"
      },
      "source": [
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTcZpGxik91S"
      },
      "source": [
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr7i2L08IIp5"
      },
      "source": [
        "## Topic 4.2 Convolutional Neural Networks (CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvht4o67PiUU"
      },
      "source": [
        "### CNN on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvnz7eV2A8LN"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOAh91fYFIii"
      },
      "source": [
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndIDOO30NRkt"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PumM6VQbBKYv"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(28, 28,1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9s56hLvCyi8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haowsN8SB5gY"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlKtXNM2g3fz"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2aSUHUah_m0"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wEuxiX_j56O"
      },
      "source": [
        "### Activity: CNN for Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN_Ku2X91WlQ"
      },
      "source": [
        "#### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkcKtFik0guh"
      },
      "source": [
        "import tensorflow as tf \n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYdyIB5_FENe"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPXFAwUl1b5V"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7ApD3saz-4b"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(32, 32,3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKwQJWPG0CB4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgQGI9_41fSJ"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcEp0NcN0RBs"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=15,validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY6tbfDe1j3k"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3dRs4J6jNMN"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlJ9Xvoa1D-P"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb"
      },
      "source": [
        "### CNN on Small Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3qK9B4liVT"
      },
      "source": [
        "#### Step 1: Import the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVgi54-2gk2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HtDXZUW2tpB"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3WCmo2nB-Q"
      },
      "source": [
        "##### ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQqwvi4270h"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xcidtPIaq0a"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91QdD90ybqp5"
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQjlvPJKbuz1"
      },
      "source": [
        "##### Visualize the raw images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmLdjVLpbxLw"
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxOO8MdJbzY-"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXGtAcmWb2fX"
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsnfnOpnb5WG"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHiuK4uTb7p_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82INGsfHb_40"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfeV7ANacCKf"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvXRTJg9cGVC"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-tecahEcFt0"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdCaSULmc786"
      },
      "source": [
        "#### Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtF0fGwac-ZG"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = 'test_dog.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = 'cat' if output == 1 else 'dog'\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print('The model prediction is ',label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ta9YWWZdbiF"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh4gu6ab9Upw"
      },
      "source": [
        "#### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0AtYM428VNi"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dmk0h7Q8dml"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtPrvH0J8hIB"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTs_1Tlg8jyX"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AazVI8CJ8m3w"
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kxSKw9i9X7F"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-y7iOf5deLP"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yfPlEvX9aQ7"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWsIEk-udhck"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P2mju029dLa"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWT8kdRsdkfs"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mpaNGixeDu"
      },
      "source": [
        "### Data Augumentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dGoE_hJ9owA"
      },
      "source": [
        "#### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGdX7q9o9quE"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQrPTa-t9tjO"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RViF2uww9zoS"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkyUlE-g4KN6"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBNK6kzB4Nrw"
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1hfKyFt9_hW"
      },
      "source": [
        "##### Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJkOuiCbf3Iq"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo"
      },
      "source": [
        "#### Step 3: Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QU9CT1u4WYH"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWN9-NfR4Z5y"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk"
      },
      "source": [
        "#### Step 5: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVpfC2X4erj"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history_augmentation.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMaVg1zTKCIG"
      },
      "source": [
        "### Activity: Dropout and Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NHy2Isf-PvH"
      },
      "source": [
        "#### Step 1: Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkCujaTvKBAK"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW-MspNP-Xik"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbpieRQj-coR"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLW6dO7GLStl"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HqV7uf--pfM"
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIHWdyGHMEE1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgZwHPBFA2K-"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF8GcV-Hw9oU"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie2rN85wA9fH"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c30ASN7WxA4z"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YnClPqDBBFX"
      },
      "source": [
        "#### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOtX3gyCMb_2"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeWq_7zY6oh"
      },
      "source": [
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7GvvcirT8Yn"
      },
      "source": [
        "#### Test the Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXrk39x7T7Ai"
      },
      "source": [
        "# Resnet Pre-trained Model\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "img_path = '/content/348291597_ee836fbb1a.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_NQzmfNULXS"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "\n",
        "img_path = '/content/guess3.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miZ1iSwnDGBP"
      },
      "source": [
        "#### Step 1: Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNtTf-B5DL0o"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfp0Rid4DQcS"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nub3z8LqDTow"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS5Q4WV4EHos"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-ggI5R8ELyR"
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_aEYm4PVptX"
      },
      "source": [
        "#### Step 2: Define the Transfer Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6b5TlezSh4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oFy8mPzroV"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(2,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spx477s2lJZh"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_rU994OlLbm"
      },
      "source": [
        "#### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbpW1JBJlN_7"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VI_2v-MlQT5"
      },
      "source": [
        "#### Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0G65Lqr0M1_"
      },
      "source": [
        "# for layer in model.layers[:20]:\n",
        "#     layer.trainable=False\n",
        "# for layer in model.layers[20:]:\n",
        "#     layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dEohjs3EQEe"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmbjR6ar2Fdo"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsnT_OzAFUFw"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiK1-F0xy83o"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliO7-3ZVY0R"
      },
      "source": [
        "#### Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_HxRBW0aGd"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = 'test_cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = 'cat' if output == 1 else 'dog'\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print('The model prediction is ',label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erM7BWgkOQzj"
      },
      "source": [
        "### Activity: Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H_tQeicOh5_"
      },
      "source": [
        "#### Step 1: Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2f4r4SgOStH"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJPr7EaOTW7"
      },
      "source": [
        "batch_size = 50\n",
        "epochs = 10\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a05a4VBfO4Bm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgo9OXG_OXio"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/dataset/Indian_currency_dataset_v1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jntaoPyLOaPS"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'training')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRf2A08LOcf7"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(\n",
        "                    rotation_range=30,\n",
        "                    width_shift_range=.30,\n",
        "                    height_shift_range=.30,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.2,\n",
        "                    rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epvDZc0dOe4_"
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5unTZaPOjhd"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1V5zIA9OnCR"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x) \n",
        "x=Dense(128,activation='relu')(x) \n",
        "preds=Dense(8,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNRgZ2hBOrPu"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poYYjdQ8OtIF"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jeay_gYfOvgT"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEH71SSrOx86"
      },
      "source": [
        "#### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzpwnPkdOz95"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3LB0tx9PgD6"
      },
      "source": [
        "#### Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN2Bgv0XPiKp"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = 'test_currency.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = {0:\"Background\",1: \"500\",2:\"50\",3:\"2000\",4:\"200\",5:\"20\",6:\"100\",7\"\"10\"}\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print('The model prediction is ',label[output])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}